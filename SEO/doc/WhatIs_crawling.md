1. How much filtering of other robots is cloudflare doing? Which mechanism for disallowing requests from crawlers are cloudflare supporting?
2. How expensive is it actually to be crawled on cloudflare? The nytimes and knuckleheads.club articles assume being crawled is expensive. Is it? How much does it cost?
Website with 1000pages?website with 1000000 pages?
And how many pages does your website have? Webshop with multiple categories and filter? Shoeshop.com with men/women/child and 30/31/32.../45/46/47. How many list pages is that?
3. Is it possible to make a crawler get only one big listing of all products?
How to guide a crawler to efficient paths, ie van the search page be different for crawler vs user?
Can
4xx and 5xx might be useful for the crawlers actually.